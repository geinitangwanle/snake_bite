#!/usr/bin/env python3
"""
AIæ·±åº¦åˆ†ææ¨¡å—
é›†æˆDeepSeek APIï¼Œæä¾›åŸºäºç”¨æˆ·ä½ç½®å’Œè›‡ç±»ç‰¹å¾çš„æ·±åº¦åˆ†æ
"""

import requests
import json
import os
import re
from typing import Optional, Dict, Any
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class AIAnalyzer:
    """AIæ·±åº¦åˆ†æå™¨ï¼Œä½¿ç”¨DeepSeek APIè¿›è¡Œåˆ†æ"""
    
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–AIåˆ†æå™¨
        
        å‚æ•°:
            api_key (str): DeepSeek APIå¯†é’¥
        """
        self.api_key = api_key or os.getenv('DEEPSEEK_API_KEY', 'sk-53fa7d59f32246f4ab6acc78bd66127e')
        self.base_url = "https://api.deepseek.com/chat/completions"
        print(f"ğŸ”‘ AIåˆ†æå™¨å·²åˆå§‹åŒ–ï¼ŒAPIå¯†é’¥: {self.api_key[:10]}...")
    
    def clean_markdown_output(self, text: str) -> str:
        """
        æ¸…ç†è¾“å‡ºæ–‡æœ¬ä¸­çš„Markdownæ ¼å¼ç¬¦å·
        
        å‚æ•°:
            text (str): åŸå§‹æ–‡æœ¬
        
        è¿”å›:
            str: æ¸…ç†åçš„æ–‡æœ¬
        """
        if not text:
            return text
        
        # ç§»é™¤äº•å·æ ‡é¢˜ç¬¦å· (# ## ### ç­‰)
        text = re.sub(r'^#{1,6}\s*', '', text, flags=re.MULTILINE)
        
        # ç§»é™¤ç²—ä½“æ ‡è®° (**)
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
        
        # ç§»é™¤æ–œä½“æ ‡è®° (*)
        text = re.sub(r'\*(.*?)\*', r'\1', text)
        
        # ç§»é™¤ä»£ç å—æ ‡è®° (```)
        text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)
        
        # ç§»é™¤è¡Œå†…ä»£ç æ ‡è®° (`)
        text = re.sub(r'`(.*?)`', r'\1', text)
        
        # ç§»é™¤é“¾æ¥æ ¼å¼ [text](url)
        text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)
        
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œï¼Œä¿æŒæœ€å¤šä¸¤è¡Œè¿ç»­ç©ºè¡Œ
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        # å»é™¤è¡Œé¦–è¡Œå°¾çš„ç©ºç™½å­—ç¬¦
        text = '\n'.join(line.strip() for line in text.split('\n'))
        
        # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºè¡Œ
        text = text.strip()
        
        return text
    
    def get_user_location(self, location_text: str = None) -> Dict[str, str]:
        """
        è·å–ç”¨æˆ·åœ°ç†ä½ç½®ä¿¡æ¯
        
        å‚æ•°:
            location_text (str): ç”¨æˆ·è¾“å…¥çš„ä½ç½®ä¿¡æ¯
        
        è¿”å›:
            dict: åŒ…å«ä½ç½®ä¿¡æ¯çš„å­—å…¸
        """
        if location_text:
            # ç”¨æˆ·æ‰‹åŠ¨è¾“å…¥ä½ç½®
            return {
                'location': location_text.strip(),
                'source': 'user_input',
                'details': f"User specified location: {location_text}"
            }
        else:
            # é»˜è®¤æç¤ºç”¨æˆ·è¾“å…¥ä½ç½®
            return {
                'location': 'Not specified',
                'source': 'unknown',
                'details': 'Please provide your specific location information in the analysis text for more accurate advice'
            }
    
    def deepseek_chat(self, message: str) -> str:
        """
        è°ƒç”¨DeepSeek APIè¿›è¡Œå¯¹è¯
        
        å‚æ•°:
            message (str): è¦å‘é€çš„æ¶ˆæ¯
        
        è¿”å›:
            str: APIè¿”å›çš„å“åº”æ¶ˆæ¯
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        data = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "user",
                    "content": message
                }
            ],
            "stream": False
        }
        
        try:
            response = requests.post(self.base_url, headers=headers, json=data)
            
            if response.status_code == 200:
                json_response = response.json()
                if "choices" in json_response and len(json_response["choices"]) > 0:
                    raw_content = json_response["choices"][0]["message"]["content"]
                    # æ¸…ç†Markdownæ ¼å¼
                    cleaned_content = self.clean_markdown_output(raw_content)
                    return cleaned_content
                else:
                    return "âŒ No content found in API response"
            else:
                return f"âŒ API call error: {response.status_code} - {response.text}"
        
        except requests.exceptions.RequestException as e:
            return f"âŒ Network request error: {e}"
        except json.JSONDecodeError as e:
            return f"âŒ JSON parsing error: {e}"
        except Exception as e:
            return f"âŒ Unknown error: {e}"
    
    def analyze_snake_encounter(self, 
                              snake_species: str,
                              confidence: str,
                              user_description: str,
                              location_info: Dict[str, str],
                              snake_knowledge: str) -> str:
        """
        åˆ†æè›‡ç±»é­é‡æƒ…å†µå¹¶æä¾›æ·±åº¦å»ºè®®
        
        å‚æ•°:
            snake_species (str): è¯†åˆ«çš„è›‡ç±»ç§ç±»
            confidence (str): è¯†åˆ«ç½®ä¿¡åº¦
            user_description (str): ç”¨æˆ·æè¿°
            location_info (dict): ä½ç½®ä¿¡æ¯
            snake_knowledge (str): è›‡ç±»çŸ¥è¯†ä¿¡æ¯
        
        è¿”å›:
            str: AIæ·±åº¦åˆ†æç»“æœ
        """
        
        # æ„å»ºåˆ†ææç¤ºè¯
        analysis_prompt = f"""
You are a professional herpetologist and wildlife safety consultant. Please provide detailed professional analysis and recommendations based on the following information:

**AI Identification Results:**
- Snake species: {snake_species}
- Identification confidence: {confidence}

**User Location Information:**
- Location: {location_info.get('location', 'Not specified')}
- Details: {location_info.get('details', 'None')}

**User Description and Questions:**
{user_description}

**Snake Basic Knowledge:**
{snake_knowledge}

Please provide professional analysis from the following aspects:

1. **Identification Result Assessment**: Verify the accuracy of AI identification based on user description, point out possible misidentification risks

2. **Regional Relevance Analysis**: Analyze the distribution and commonness of this snake species in the local area based on user location

3. **Immediate Safety Advice**: Emergency response plan for the current situation

4. **Behavior Prediction**: Predict possible snake behavior based on environment and season

5. **Prevention Measures**: Long-term prevention recommendations for this region

6. **Medical Advice**: If it's a venomous snake species, provide specific medical treatment recommendations

7. **Ecological Value**: Explain the ecological role and conservation significance of this snake species

Please respond in English with professional but understandable language, emphasizing safety recommendations. If information is insufficient, please clearly indicate what additional information is needed to provide more accurate advice. Please do not use Markdown formatting, respond with plain text only.
"""
        
        print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨DeepSeek APIè¿›è¡Œæ·±åº¦åˆ†æ...")
        return self.deepseek_chat(analysis_prompt)
    
    def quick_safety_check(self, snake_species: str, user_location: str) -> str:
        """
        å¿«é€Ÿå®‰å…¨æ£€æŸ¥
        
        å‚æ•°:
            snake_species (str): è›‡ç±»ç§ç±»
            user_location (str): ç”¨æˆ·ä½ç½®
        
        è¿”å›:
            str: å¿«é€Ÿå®‰å…¨å»ºè®®
        """
        safety_prompt = f"""
A user encountered {snake_species} in {user_location}. Please provide immediate safety advice (within 100 words):
1. Is it venomous?
2. What should they do immediately?
3. What should they NOT do?

Please respond in English and do not use any Markdown formatting symbols.
"""
        return self.deepseek_chat(safety_prompt)

# åˆ›å»ºå…¨å±€AIåˆ†æå™¨å®ä¾‹
ai_analyzer = AIAnalyzer()

# æµ‹è¯•å‡½æ•°
def test_analyzer():
    """æµ‹è¯•AIåˆ†æå™¨åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•AIåˆ†æå™¨...")
    
    # æµ‹è¯•åŸºç¡€å¯¹è¯
    response = ai_analyzer.deepseek_chat("Hello, please introduce yourself briefly.")
    print(f"åŸºç¡€å¯¹è¯æµ‹è¯•: {response[:100]}...")
    
    # æµ‹è¯•ä½ç½®è·å–
    location = ai_analyzer.get_user_location("Beijing, Chaoyang District")
    print(f"ä½ç½®ä¿¡æ¯: {location}")
    
    # æµ‹è¯•Markdownæ¸…ç†åŠŸèƒ½
    test_text = "## This is a title\n\n**This is bold** content\n\n*This is italic*\n\n`code` content\n\n```\ncode block\n```\n\n[link](http://example.com)"
    cleaned = ai_analyzer.clean_markdown_output(test_text)
    print(f"Markdownæ¸…ç†æµ‹è¯•:")
    print(f"åŸæ–‡: {test_text}")
    print(f"æ¸…ç†å: {cleaned}")

if __name__ == "__main__":
    test_analyzer() 